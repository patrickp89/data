---
title: "Data analysis: ebuy's sales data"
output:
  bookdown::html_document2:
    toc: yes
---

# Data Manipulation
```{r includse01, message=FALSE}
library(dplyr)
library(ggplot2)
library(tidyr)
```

# Summary Statistics

# Plots

# Models and Prediction
To train our models and make predictions we have to load additional libraries:
```{r includse02, message=FALSE}
library(caret)
library(tidyverse)
library(rpart)
library(rpart.plot)
```

## Load Data and Recode Variables
We first load the data and pick the columns that we are interested in:
```{r}
orderDf <- read.csv(file="../data/interim/orders/orders_cleaned.csv", sep=",", na.strings=c("?","NA"))
partialOrdersDf <- orderDf[c("Product_Family_ID",
                             "Order_Line_Day_of_Week",
                             "Order_Line_Hour_of_Day",
                             "Product_ID",
                             "Gender",
                             "US_State",
                             "Age")]
```

Some of the variables have to be forced to be categorical:
```{r}
partialOrdersDf$Product_Family_ID <- as.factor(partialOrdersDf$Product_Family_ID)
partialOrdersDf$Order_Line_Day_of_Week <- as.factor(partialOrdersDf$Order_Line_Day_of_Week)
partialOrdersDf$Order_Line_Hour_of_Day <- as.factor(partialOrdersDf$Order_Line_Hour_of_Day)
partialOrdersDf$Gender <- as.factor(partialOrdersDf$Gender)
partialOrdersDf$US_State <- as.factor(partialOrdersDf$US_State)
partialOrdersDf$Age <- as.numeric(partialOrdersDf$Age)
summary(partialOrdersDf)
```

## Training the Model
We first grow a large tree with a complexity parameter of cp=0.0001 (i.e. splits must decrease the lack of fit by factor cp=0.0001):
```{r}
tree <- rpart(Product_Family_ID ~ Order_Line_Day_of_Week + Gender + Age,
              method="class",
              data=partialOrdersDf,
              cp=0.0001)
```

We than examine the results of a 10-fold cross-validation by plotting the complexity parameter vs. its cross-validated error:
```{r}
plotcp(tree)
```

To prevent over-fitting, we choose the leftmost cp value below the dotted line (cp=0.001): a tree of that size (here: 36 splits) is the smallest tree whose cross-validated error is whithin one standard error of the minimum cross-validated error value. We than prune the tree to its new size:
```{r}
prunedTree <- prune(tree, cp=0.001)
```

And pretty-print the resulting tree:
```{r}
prp(prunedTree)
```
