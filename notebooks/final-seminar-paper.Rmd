---
title: "Data analysis: ebuy's sales data"
bibliography: "bibliographies/literature.bib"
output:
  bookdown::html_document2:
    toc: yes
    theme: spacelab
---

# Data Manipulation
```{r includse01, message=FALSE}
library(dplyr)
library(ggplot2)
library(tidyr)
library(usmap)
library(knitr)
```

# Summary Statistics

```{r}
clickstream_data <- read.csv(file="../data/interim/clickstream/clickstream_cleaned.csv", sep=",", na.strings=c("NA"))
```

## Clickstream

```{r summarytable1, echo=FALSE}

table_data <- clickstream_data %>%
  select(Request_Processing_Time, Request_Sequence, REQUEST_HOUR_OF_DAY) %>%
  transmute(mean_RPT = mean(Request_Processing_Time), mean_RS = mean(Request_Sequence), mean_HOD = mean(REQUEST_HOUR_OF_DAY),
            sd_RPT = sd(Request_Processing_Time), sd_RS = sd(Request_Sequence), sd_HOD = sd(REQUEST_HOUR_OF_DAY),
            min_RPT = min(Request_Processing_Time), min_RS = min(Request_Sequence), min_HOD = min(REQUEST_HOUR_OF_DAY),
            max_RPT = max(Request_Processing_Time), max_RS = max(Request_Sequence), max_HOD = max(REQUEST_HOUR_OF_DAY))

table_data <- table_data[1,] %>%
  gather("column", "mean", 1:3) %>% 
  gather("sd_data", "sd", 1:3) %>% 
  gather("min_data", "min", 1:3) %>% 
  gather("max_data", "max", 1:3) %>%
  mutate(column = sapply(strsplit(column, "_"), "[", 2),
         sd_data = sapply(strsplit(sd_data, "_"), "[", 2),
         min_data = sapply(strsplit(min_data, "_"), "[", 2),
         max_data = sapply(strsplit(max_data, "_"), "[", 2)) %>%
  filter(column == sd_data & column == min_data & column == max_data) %>%
  select(column, mean, sd, min, max)

kable(table_data)
  
```


# Plots

## Clickstream

```{r heatmap, echo=FALSE}


map_data <- clickstream_data %>%
  select(US_State) %>%
  group_by(US_State) %>%
  summarise(Request_Count = n(), state = first(US_State))

plot_usmap(data = map_data, values = "Request_Count", labels = TRUE) +
  scale_fill_continuous(low = "white", high = "red", name = "average Order Amount") +
  labs(title = "How much money do customers from different states spend?",
       subtitle = "Average order amount split by US State") +
  theme(plot.title = element_text(face = "bold", size = 15, hjust = 0.5),
        plot.subtitle = element_text(hjust = 0.5, size = 12, face = "italic"),
        legend.position = "bottom", legend.justification = "center",
        legend.background = element_blank())

```

```{r requests, echo = FALSE}

data_requests_products <- clickstream_data %>%
  select(Product_ID) %>%
  filter(Product_ID != "?") %>%
  group_by(Product_ID) %>%
  summarise(Request_Count = n())

ggplot(data_requests_products) +
  geom_line(aes(x = reorder(Product_ID, desc(Request_Count)), y = Request_Count, group = 1)) +
  labs(x = "Products", y = "Requests",
       title = "How many times was each product accessed?",
       subtitle = "Requests per product")  +
  theme_classic() +
  theme(axis.text.x = element_blank(), axis.ticks.x = element_blank(),
        plot.title = element_text(hjust = 0.5), plot.subtitle = element_text(hjust = 0.5)) +
  scale_y_continuous(expand = c(0,0))

```

```{r sessionduration, echo=FALSE}
  duration_data <- clickstream_data %>%
  select(Session_ID, Request_Sequence, Request_Date, Request_Date_Time, Session_First_Request_Date, Session_First_Request_Date_Time) %>%
  unite(col = "Request_Timestamp",c("Request_Date", "Request_Date_Time"), sep = " ", remove = TRUE) %>%
  unite(col="Session_First_Request_Timestamp", c("Session_First_Request_Date","Session_First_Request_Date_Time"), sep=" ", remove=TRUE) %>%
  mutate(Request_Timestamp = as.POSIXct(Request_Timestamp, format="%Y-%m-%d %H\\:%M\\:%S")) %>%
  mutate(Session_First_Request_Timestamp = as.POSIXct(Session_First_Request_Timestamp, format="%Y-%m-%d %H\\:%M\\:%S")) %>%
  group_by(Session_ID) %>%
  summarise(Pages_Visited=n(),Session_First_Request=min(Session_First_Request_Timestamp),Session_Last_Request=max(Request_Timestamp)) %>%
  mutate(Session_Duration = as.numeric(difftime(Session_Last_Request, Session_First_Request,units = "secs",))) %>%
  group_by(Pages_Visited) %>%
  summarise(avg_Session_Duration = mean(Session_Duration), Session_Count = n_distinct(Session_ID)) %>%
  filter(Session_Count > 2 & Pages_Visited > 1)
  
  ggplot(data = duration_data) +
  geom_point(aes(x = Pages_Visited, y = avg_Session_Duration, size = Session_Count)) +
  labs(x = "Pages Visited", y = "average Session Duration (seconds)", size = "Sessions",
       title = "How long do customers stay on the site?",
       subtitle = "Average session duration per session page visits") +
  theme(plot.title = element_text(hjust = 0.5), plot.subtitle = element_text(hjust = 0.5))
```

## What are the most popular brands for men and women?
### Women

```{r include=FALSE}
library(ggplot2)
library(dplyr)
library(tidyverse)
library(stringr)
orders = read.csv("../data/interim/orders/orders_cleaned.csv")
orders = orders %>% select(Customer_ID, Order_Line_Session_ID, Order_ID, Customer_ID, Age, Gender, Product_Level_2_Path, Order_Status, Order_Line_Quantity)
orders$Brand = unlist(lapply(orders$Product_Level_2_Path, FUN = function(path){return(str_match(path, "\\/.*\\/.*\\/(.*)")[,2])}))
```

To get an overview over what brands your customers like the most we vizualized the popularity of the brands based on how often they get purchased.
```{r include= FALSE}
mostPopularFemaleBrands = orders %>% 
  filter(Gender == "Female") %>%
  filter(!is.na(Brand)) %>%
  group_by(Brand) %>%
  summarise(Order_Amount = sum(Order_Line_Quantity)) %>%
  arrange(desc(Order_Amount)) %>%
  head(10)
```

```{r echo=FALSE}
mostPopularFemaleBrands
```

```{r echo=FALSE}
ggplot(mostPopularFemaleBrands, mapping = aes(x = reorder(Brand, Order_Amount), y = Order_Amount, fill = Brand)) + 
  geom_bar(stat = "identity") +
  coord_flip() +
  labs(title = "Most Popular Female Brands", x = "Brand", y = "Number of Purchases")
```

### Men
```{r include=FALSE}
mostPopularMaleBrands = orders %>%
  filter(Gender == "Male") %>%
  filter(!is.na(Brand)) %>%
  group_by(Brand) %>%
  summarise(Order_Amount = sum(Order_Line_Quantity)) %>%
  arrange(desc(Order_Amount)) %>%
  head(10)
```


```{r echo=FALSE}
ggplot(mostPopularMaleBrands, mapping = aes(x = reorder(Brand, Order_Amount), y = Order_Amount, fill = Brand)) + 
  geom_bar(stat = "identity") +
  coord_flip() +
  labs(title = "Most Popular Male Brands", x = "Brand", y = "Number of Purchases")
```


# Comparison of Groups
After loading the "experimental_results" dataset we decided to keep the first ID column.
```{r loadexpdata, message=FALSE}
experimentDf <- read.csv(file="../experiment/experimental_results.csv", sep=",", na.strings=c("NA"))
partialExperimentDf <- experimentDf[c("id_",
                                      "ranking_based",
                                      "random_recommendations",
                                      "profit_oriented")]

names(partialExperimentDf)[1] <- "id"
partialExperimentDf$id <- as.factor(partialExperimentDf$id)
summary(partialExperimentDf)
```

We then compared the results of both the ranking-based as well as the profit-oriented recommender systems against the results of the baseline recommender system (that selects products randomly).
```{r}
t.test(partialExperimentDf$random_recommendations, partialExperimentDf$ranking_based)
t.test(partialExperimentDf$random_recommendations, partialExperimentDf$profit_oriented)
```
The mean values (i.e. sales) of the profit-oriented recommender system and the baseline recommender system are not equal (p<0.00001), while the same hypothesis could not be rejected for the comparison of the ranking-based and the baseline recommender system (p=0.08). As the profit-oriented recommender systems mean value (21.75) is greater than the baseline mean (17.91), ebuy should preferably use the profit-oriented one.


# Models and Prediction
To train our models and make predictions we have to load additional libraries:
```{r includse02, message=FALSE}
library(caret)
library(tidyverse)
library(rpart)
library(rpart.plot)
```

## Load Data and Recode Variables
We first load the data and pick the columns that we are interested in:
```{r}
orderDf <- read.csv(file="../data/interim/orders/orders_cleaned.csv", sep=",", na.strings=c("?","NA", "NULL"))
partialOrdersDf <- orderDf[c("Product_Family_ID",
                             "Order_Line_Day_of_Week",
                             "Order_Line_Hour_of_Day",
                             "Order_Line_Amount",
                             "Product_ID",
                             "Gender",
                             "US_State",
                             "Age")]
```

Some of the variables have to be forced to be categorical:
```{r}
partialOrdersDf$Product_Family_ID <- as.factor(partialOrdersDf$Product_Family_ID)
partialOrdersDf$Order_Line_Day_of_Week <- as.factor(partialOrdersDf$Order_Line_Day_of_Week)
partialOrdersDf$Order_Line_Hour_of_Day <- as.factor(partialOrdersDf$Order_Line_Hour_of_Day)
partialOrdersDf$Gender <- as.factor(partialOrdersDf$Gender)
partialOrdersDf$US_State <- as.factor(partialOrdersDf$US_State)
partialOrdersDf$Age <- as.numeric(partialOrdersDf$Age)
summary(partialOrdersDf)
```

## Training the Model
As ebuy's products fall into certain product families, we trained a model that allows to predict for a new customer from which product family he will purchase a product. We first grew a large tree with a complexity parameter of cp=0.0001 (i.e. splits had to decrease the lack of fit by a factor of 0.00001):
```{r}
tree <- rpart(Product_Family_ID ~ Order_Line_Day_of_Week + Gender + Age,
              method="class",
              data=partialOrdersDf,
              cp=0.00001)
```

We then examined the results of a 10-fold cross-validation by plotting the complexity parameter vs. its cross-validated error (as shown in figure \@ref(fig:cpplottree1)).
```{r cpplottree1, echo=FALSE, fig.cap="Product Family ID: Complexity parameter vs. cross-validated error"}
plotcp(tree)
```

To prevent over-fitting, @kabacoff2015 suggests to choose the leftmost cp value below the dotted line (here: cp=0.001): a tree of that size (here: 41 splits) is the smallest tree whose cross-validated error is whithin one standard error of the minimum cross-validated error value. We therfore pruned the tree to its new size and pretty-printed the resulting tree (figure \@ref(fig:prunedtree1)).
```{r prunedtree1, echo=FALSE, fig.cap="Product Family ID: Pruned Classification Tree"}
prune(tree, cp=0.001) %>%
  prp(.)
```

Next we computed a linear regression model that helped us understand, how the different properties of customers affected the amount of money they would spend in total.
```{r}
# enable cross validation and set the number of folds:
ctrl <- trainControl(method = "cv",
                     number = 10)

# preform a linear regression:
linreg1 <- train(Order_Line_Amount ~ Age + Gender,
                 data = partialOrdersDf,
                 trControl = ctrl,
                 na.action  = na.pass,
                 method = "lm")
linreg1
linreg1$finalModel
```

# Summary

# Literature
